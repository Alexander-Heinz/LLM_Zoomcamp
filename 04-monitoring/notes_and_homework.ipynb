{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring answer quality of LLMs\n",
    "- different types of quality metrics:\n",
    "    - Vector similarity between expected and LLM answer\n",
    "    - LLM-as-a-judge to compute toxicity of LLM answer\n",
    "    - LLM-as-a-judge to assess quality of LLM answer\n",
    "\n",
    "- store computed metrics in relational database\n",
    "- use grafana to visualize metrics over time\n",
    "\n",
    "Monitoring answer quality with user feedback\n",
    "- store chat sessions and collect user feedback in database\n",
    "- use grafana to visualize user feedback and corresponding chat sessions\n",
    "\n",
    "What else is there?\n",
    "- further quality metrics  & user feedback\n",
    "    - i.e. bias and fairness, topic clustering, textual user feedback\n",
    "    - system metrics: latency, traffic, errors, saturation (also referred to as \"4x golden signals)\n",
    "    - *cost* of used infrastructure, i.e. vector store and LLM API -> see more details on (https://www.linkedin.com/in/magdalenakuhn)[here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline / Online evaluation\n",
    "\n",
    "\n",
    "recap:\n",
    "\n",
    "1. get a RAG \n",
    "\n",
    "2. evaluate retrieval\n",
    "- hitrate\n",
    "- mrr (mean reciprocal rank)\n",
    "\n",
    "3. monitor / evaluate the prompt\n",
    "\n",
    "- offline evaluation\n",
    "    - cosine similarity (closeness of answer to the expectation)\n",
    "    - LLM as a judge\n",
    "\n",
    "- online evaluation\n",
    "    - A/B tests, experiments\n",
    "    - user feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline (RAG) evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(q):\n",
    "    search_results = search(q)\n",
    "    prompt = build_prompt(q, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook `offline-rag-evaluation.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cosine similarity between LLM Answer & Original (Expected) answer\n",
    "- loop over questions & save cosine similarity\n",
    "- 1830 documents cost quite something (3.5 is cheaper)\n",
    "- cost ~10€ for 4o\n",
    "- 3.5 costs 10 times less (about 1€)\n",
    "- 4o mini is even cheaper (30 cents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A -> Q -> A' cosine similarity(A, A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use `.describe()` to see stats (mean similarity, min, max ...)\n",
    "- use seaborn to build histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-as-a-judge:\n",
    "- prompt ChatGPT if the answer is relevant with the reason for the evaluation. Give both answer and ground truth.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "github_url = \"https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv\"\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  The context does not provide any specific info...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:300]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, get the embeddings model `multi-qa-mpnet-base-dot-v1` from the Sentence Transformer library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_name = \"multi-qa-mpnet-base-dot-v1\"\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What's the first value of the resulting vector?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42244643"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm = df.iloc[0].answer_llm\n",
    "embeddings = embedding_model.encode(answer_llm)\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Computing the dot product\n",
    "Now for each answer pair, let's create embeddings and compute dot product between them\n",
    "\n",
    "We will put the results (scores) into the evaluations list\n",
    "\n",
    "What's the 75% percentile of the score?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  The context does not provide any specific info...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75th Percentile Score: 31.67430305480957\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "scores = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    answer_llm = df.iloc[i].answer_llm\n",
    "    answer_orig = df.iloc[i].answer_orig\n",
    "    \n",
    "    # Generate embeddings\n",
    "    answer_llm_embeddings = embedding_model.encode(answer_llm)\n",
    "    answer_orig_embeddings = embedding_model.encode(answer_orig)\n",
    "    \n",
    "    # Calculate dot product (cosine similarity)\n",
    "    similarity_score = np.dot(answer_llm_embeddings, answer_orig_embeddings)\n",
    "    scores.append(similarity_score)\n",
    "\n",
    "# Calculate the 75th percentile of the scores\n",
    "percentile_75 = np.percentile(scores, 75)\n",
    "print(\"75th Percentile Score:\", percentile_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75th Percentile Cosine Similarity: 0.8362346738576889\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_vector(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    return v / norm\n",
    "\n",
    "# Assuming `embedding_model` is already defined and has the `encode` method.\n",
    "# Also assuming `df` is your dataframe.\n",
    "\n",
    "cosine_similarities = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    answer_llm = df.iloc[i].answer_llm\n",
    "    answer_orig = df.iloc[i].answer_orig\n",
    "    \n",
    "    # Generate embeddings\n",
    "    answer_llm_embeddings = embedding_model.encode(answer_llm)\n",
    "    answer_orig_embeddings = embedding_model.encode(answer_orig)\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    answer_llm_embeddings_norm = normalize_vector(answer_llm_embeddings)\n",
    "    answer_orig_embeddings_norm = normalize_vector(answer_orig_embeddings)\n",
    "    \n",
    "    # Calculate cosine similarity (dot product of normalized vectors)\n",
    "    cosine_similarity = np.dot(answer_llm_embeddings_norm, answer_orig_embeddings_norm)\n",
    "    cosine_similarities.append(cosine_similarity)\n",
    "\n",
    "# Calculate the 75th percentile of the cosine similarities\n",
    "percentile_75 = np.percentile(cosine_similarities, 75)\n",
    "print(\"75th Percentile Cosine Similarity:\", percentile_75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will explore an alternative metric - the ROUGE score.\n",
    "\n",
    "This is a set of metrics that compares two answers based on the overlap of n-grams, word sequences, and word pairs.\n",
    "\n",
    "It can give a more nuanced view of text similarity than just cosine similarity alone.\n",
    "\n",
    "We don't need to implement it ourselves, there's a python package for it:\n",
    "\n",
    "`pip install rouge`\n",
    "(The latest version at the moment of writing is 1.0.1)\n",
    "\n",
    "Let's compute the ROUGE score between the answers at the index 10 of our dataframe (doc_id=5170565b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "r = df.iloc[10]\n",
    "\n",
    "\n",
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454544954545456"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"rouge-1\"][\"f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r    0.3549\n",
       "p    0.3549\n",
       "f    0.3549\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(scores).mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three scores: rouge-1, rouge-2 and rouge-l, and precision, recall and F1 score for each.\n",
    "\n",
    "rouge-1 - the overlap of unigrams,\n",
    "rouge-2 - bigrams,\n",
    "rouge-l - the longest common subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-2 Score: 0.2069650198342332\n"
     ]
    }
   ],
   "source": [
    "# Lists to store the scores\n",
    "rouge_1_scores = []\n",
    "rouge_2_scores = []\n",
    "rouge_l_scores = []\n",
    "\n",
    "# Compute ROUGE scores for all records\n",
    "for i in range(len(df)):\n",
    "    r = df.iloc[i]\n",
    "    scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "    rouge_1 = scores['rouge-1']['f']\n",
    "    rouge_2 = scores['rouge-2']['f']\n",
    "    rouge_l = scores['rouge-l']['f']\n",
    "    \n",
    "    # Append scores to lists\n",
    "    rouge_1_scores.append(rouge_1)\n",
    "    rouge_2_scores.append(rouge_2)\n",
    "    rouge_l_scores.append(rouge_l)\n",
    "\n",
    "# Calculate the average ROUGE-2 score\n",
    "average_rouge_2 = sum(rouge_2_scores) / len(rouge_2_scores)\n",
    "print(\"Average ROUGE-2 Score:\", average_rouge_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
